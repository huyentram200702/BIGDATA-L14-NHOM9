{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtap63bYWEz0"
      },
      "source": [
        "# CS246 - Homework 1\n",
        "\n",
        "## Question 2\n",
        "\n",
        "### Association Rules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HZwEMxqdlz6"
      },
      "source": [
        "### Answer section a. b. c."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. A drawback of using confidence is that it ignores Pr(B). Why is this a drawback? Explain why lift and conviction do not suffer from this drawback.**\n",
        "\n",
        "`Một nhược điểm của việc sử dụng độ tin cậy (Confidence) đó là bỏ qua Pr(B). Đây là nhược điểm, vì sao? Giải thích tại sao Lift và Conviction không bị nhược điểm này?`\n",
        "\n",
        "Việc sử dụng độ tin cậy trong phân tích luật kết hợp có một hạn chế là bỏ qua xác suất của Pr(B). Điều này có thể dẫn đến việc đánh giá sai mối quan hệ giữa các mục trong tập dữ liệu.\n",
        "\n",
        "Để hiểu rõ hơn, giả sử rằng trong tập dữ liệu của bạn, mục A và mục B không có mối quan hệ với nhau. Tuy nhiên, do sự chênh lệch về tần suất của các mục, độ tin cậy của quy tắc kết hợp giữa A và B có thể rất cao, vì nó dựa trên tần suất xuất hiện của mục A.\n",
        "\n",
        "Ví dụ, nếu mục A xuất hiện rất nhiều trong tập dữ liệu, nhưng mục B xuất hiện rất ít, độ tin cậy của quy tắc kết hợp giữa A và B có thể rất cao. Tuy nhiên, đây chỉ là một kết quả ngẫu nhiên do sự chênh lệch trong tần suất xuất hiện của các mục, chứ không phải do có mối quan hệ giữa A và B.\n",
        "\n",
        "Vì vậy, để đánh giá mối quan hệ giữa các mục một cách chính xác, ngoài độ tin cậy, cần phải sử dụng các độ đo khác như mức tăng (Lift) và niềm tin (Confidence) để đánh giá xác suất xuất hiện của các mục và mối quan hệ giữa chúng. \n",
        "\n",
        "Vì vậy, Lift và Conviction giúp khắc phục nhược điểm của Confidence bằng cách tính toán thêm xác suất của Pr(B) vào công thức tính toán. Lift cho ta biết mức độ ảnh hưởng của mặt hàng A đến mặt hàng B, trong khi Conviction cho ta biết độ tin cậy của luật kết hợp đó."
      ],
      "metadata": {
        "id": "jXPX2_GYd3OZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. A measure is symmetrical if measure(A → B) = measure(B → A). Which of the measures presented here are symmetrical? For each measure, please provide either a proof that the measure is symmetrical, or a counterexample that shows the measure is not symmetrical.**\n",
        "\n",
        "`Một đại lượng được gọi là đối xứng nếu (A → B) = (B → A). Công thức nào được trình bày ở đây là đối xứng? Đối với mỗi công thức, hãy chứng minh cho thấy công thức đó là đối xứng hoặc một ví dụ biện chứng cho thấy công thức đó không đối xứng.`\n",
        "\n",
        "Lift là một độ đo đối xứng. Confidence và conviction không phải là độ đo đối xứng vì chúng có tính định hướng, trong khi lift lại không có tính định  hướng. Cụ thể:\n",
        "\n",
        "1. Lift(A → B) = Lift(B → A) = Pr(A ∩ B) / (Pr(A) x Pr(B)).\n",
        "\n",
        "2. Conf(A → B) = Pr(B|A) và conf(B → A) = Pr(A|B). Pr(A|B) và Pr(B|A) có thể khác nhau.\n",
        "\n",
        "3. Conv dựa trên conf và có tính định hướng.\n",
        "\n",
        "Ví dụ: Nếu chúng ta có các giỏ hàng AB, AC, AD, thì S(A) = 3/3, S(B) = 1/3 và Pr(A ∩ B) = 1/3. Sau đó, confe(A → B) = Pr(B|A)  ≠ Pr(A|B) = conf(B → A) vì 1/3:3/3 ≠  1/3:1/3.\n",
        "\n",
        "Tương tự, conv(A → B) = 1 - S(B) / (1 - confidence(A → B)) ≠ 1 - S(A) / (1 - conf(B → A)) = conv(B → A) vì 1 - 1/3 : 1 - 1/2 = 4/3 không bằng 1 - 2/3 : 1 - 1 = inf.\n",
        "\n"
      ],
      "metadata": {
        "id": "NNREWZ8of3Eu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c. Perfect implications are rules that hold 100% of the time (or equivalently, the associated conditional probability is 1). A measure is desirable if it reaches its maximum achievable value for all perfect implications. This makes it easy to identify the best rules. Which of the above measures have this property? You may ignore 0/0 but not other infinity cases. Also you may find it easy to explain by an example.**\n",
        "\n",
        "`Hàm ý hoàn hảo là các quy tắc giữ đúng 100% thời gian (hoặc tương đương, xác suất có điều kiện liên quan là 1). Một công thức được thỏa mãn nếu nó đạt đến giá trị tối đa có thể đạt được cho tất cả các hàm ý hoàn hảo. Điều này giúp dễ dàng xác định các công thức tốt nhất. Công thức nào trong số các công thức trên có tính chất này? Bạn có thể bỏ qua 0/0 nhưng không thể bỏ qua các trường hợp vô cực khác. Ngoài ra, bạn có thể dễ dàng giải thích bằng một ví dụ.`\n",
        "\n",
        "Conviction và Confidence thỏa mãn được trong khi Lift thì không. Nếu B xảy ra mỗi thời điểm A xảy ra (nghĩa là Pr(B|A) = 1) thì: \n",
        "\n",
        "1. conf(A→B) = 1\n",
        "\n",
        "2. conv(A→B)→infinity\n",
        "\n",
        "3. lift(A→B) phụ thuộc vào giá trị của Pr(B) và có thể khác vì B có thể xảy ra trong các giỏ không có A.\n",
        "\n",
        "Ví dụ:\n",
        "\n",
        "Nếu chúng ta có các giỏ hàng AB, AB, CD, EF thì Pr(B|A) = 1, S(B) = 1/2, Pr(D|C) = 1, và S(D) = 1/4.\n",
        "\n",
        "Sau đó, lift(A→B) = 1 : 1/2 = 2 và lift(C→D) = 1 : 1/4 = 4. Mặc dù cả hai quy tắc đều là quy tắc 100% nhưng chúng có tỉ lệ Lift khác nhau.\n"
      ],
      "metadata": {
        "id": "glkVET9XgLgS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-YhEpP_Ds-"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFeA3Y_Mdl0A"
      },
      "source": [
        "Let's setup Spark on your Colab environment.  Run the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqWG0wxDnqFE"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYRqHUPMoDrR"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8YewevWqi66"
      },
      "source": [
        "Download the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VN9w0zTqRXv"
      },
      "source": [
        "id='1MzcgkUnI8HsPiQBf6hrwDKvsw3145eIH'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('browsing.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_4lW24LmYVC"
      },
      "source": [
        "Import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo1c66c0rUsh"
      },
      "source": [
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext\n",
        "from pyspark.mllib.fpm import FPGrowth\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from functools import cmp_to_key\n",
        "\n",
        "# create the Spark Session\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# create the Spark Context\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCngWmwdreOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42842d07-5529-4c76-cb2d-ca5c37bf4b2b"
      },
      "source": [
        "test_file_name= \"/content/browsing.txt\"\n",
        "f = open(test_file_name, 'r')\n",
        "\n",
        "#đếm số lần xuất hiện của mỗi phần tử (item)\n",
        "Countitem = {}\n",
        "for l in f:\n",
        "    items = l.strip().split(\" \")\n",
        "    for item in items:\n",
        "        if item in Countitem:\n",
        "            Countitem[item] = Countitem[item] + 1\n",
        "        else:\n",
        "            Countitem[item] = 1\n",
        "\n",
        "#tạo ra tập các phần tử (items) phổ biến từ tập dữ liệu và một ngưỡng (threshold) s cho trước.\n",
        "Frequentitem= {}\n",
        "for item in Countitem:\n",
        "    if Countitem[item] > s:\n",
        "        Frequentitem[item] = Countitem[item]\n",
        "\n",
        "#đếm số lần xuất hiện của các cặp phần tử (pairs) phổ biến trong tập dữ liệu\n",
        "f.seek(0)\n",
        "Countpair = {}\n",
        "for l in f:\n",
        "    items = l.strip().split(\" \")\n",
        "    index=len(items);\n",
        "    for i in range(index):\n",
        "        for j in range(i + 1, index):\n",
        "            if (items[i] in Frequentitem) and (items[j] in Frequentitem):\n",
        "                key = (items[i], items[j])\n",
        "                if key in Countpair:\n",
        "                    Countpair[key] = Countpair[key] + 1\n",
        "                else:\n",
        "                    Countpair[key] = 1\n",
        "                key = (items[j], items[i])\n",
        "                if key in Countpair:\n",
        "                    Countpair[key] = Countpair[key] + 1\n",
        "                else:\n",
        "                    Countpair[key] = 1\n",
        "\n",
        "'''Tạo ra một từ điển (dictionary) Frequentpair chứa các cặp phần tử (pairs) phổ biến trong tập dữ liệu. \n",
        "Một cặp được coi là phổ biến nếu số lần xuất hiện của cặp đó trong tập dữ liệu lớn hơn một ngưỡng (threshold) s.'''\n",
        "Frequentpair = {}\n",
        "for key in Countpair:\n",
        "    if Countpair[key] > s:\n",
        "        Frequentpair[key] = Countpair[key]\n",
        "\n",
        "#Tính toán frequent pair of items thường xuất hiện trong tập dữ liệu\n",
        "confidence = []\n",
        "for key, val in Frequentpair.items():\n",
        "    itemA= key[0]\n",
        "    itemB = key[1]\n",
        "    prob = val / (1.0 * Frequentitem[itemA])\n",
        "    confidence.append((itemA, prob, itemB))\n",
        "\n",
        "print(\"The top 5 rules are as follows\")\n",
        "sortListL2 = sorted(confidence, key=lambda x:x[1], reverse = True)\n",
        "for i in range(5):\n",
        "    print(str(sortListL2[i][0]) + \" ⇒ \" + str(sortListL2[i][2]) + \"   \" + str(sortListL2[i][1]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top 5 rules are as follows\n",
            "DAI93865 ⇒ FRO40251   1.0\n",
            "GRO85051 ⇒ FRO40251   0.999176276771005\n",
            "GRO38636 ⇒ FRO40251   0.9906542056074766\n",
            "ELE12951 ⇒ FRO40251   0.9905660377358491\n",
            "DAI88079 ⇒ FRO40251   0.9867256637168141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Triple Rules\n",
        "'''Thực hiện tìm kiếm tập ba phần tử (triple) phổ biến từ tập dữ liệu (dataset). \n",
        "Cụ thể, với mỗi dòng trong dataset, chương trình sẽ tách thành các phần tử và duyệt qua tất cả các cặp phần tử (pair) khác nhau trong dòng đó. \n",
        "Sau đó, chương trình lại duyệt qua tất cả các cặp phần tử khác nhau trong dòng đó để tìm các tập ba phần tử (triple) chứa các cặp phần tử phổ biến. \n",
        "Cuối cùng, chương trình sẽ đếm số lần xuất hiện của mỗi tập ba phần tử (triple) phổ biến và lưu vào từ điển Counttriple.'''\n",
        "f.seek(0)\n",
        "Counttriple = {}\n",
        "for l in f:\n",
        "    items = l.strip().split(\" \")\n",
        "    for i in range(len(items)):\n",
        "        for j in range(i + 1, len(items)):\n",
        "            for k in range(j + 1, len(items)):\n",
        "                pair1 = (items[i], items[j])\n",
        "                pair2 = (items[i], items[k])\n",
        "                pair3 = (items[j], items[k])\n",
        "                if (pair1 in Frequentpair) and (pair2 in Frequentpair) and (pair3 in Frequentpair):\n",
        "                    key = (items[i], items[j], items[k])\n",
        "                    if key in Counttriple:\n",
        "                        Counttriple[key] = Counttriple[key] + 1\n",
        "                    else:\n",
        "                        Counttriple[key] = 1\n",
        "\n",
        "                    key = (items[i], items[k], items[j])\n",
        "                    if key in Counttriple:\n",
        "                        Counttriple[key] = Counttriple[key] + 1\n",
        "                    else:\n",
        "                        Counttriple[key] = 1\n",
        "\n",
        "                    key = (items[k], items[i], items[j])\n",
        "                    if key in Counttriple:\n",
        "                        Counttriple[key] = Counttriple[key] + 1\n",
        "                    else:\n",
        "                        Counttriple[key] = 1\n",
        "\n",
        "                    key = (items[k], items[j], items[i])\n",
        "                    if key in Counttriple:\n",
        "                        Counttriple[key] = Counttriple[key] + 1\n",
        "                    else:\n",
        "                        Counttriple[key] = 1\n",
        "\n",
        "                    key = (items[j], items[i], items[k])\n",
        "                    if key in Counttriple:\n",
        "                        Counttriple[key] = Counttriple[key] + 1\n",
        "                    else:\n",
        "                        Counttriple[key] = 1\n",
        "\n",
        "                    key = (items[j], items[k], items[i])\n",
        "                    if key in Counttriple:\n",
        "                        Counttriple[key] = Counttriple[key] + 1\n",
        "                    else:\n",
        "                        Counttriple[key] = 1\n",
        "\n",
        "#tính toán số lần xuất hiện của các bộ ba phổ biến (gọi là Frequenttriple) trong tập dữ liệu\n",
        "Frequenttriple = {}\n",
        "for key in Counttriple:\n",
        "    if Counttriple[key] > s:\n",
        "        Frequenttriple[key] = Counttriple[key]\n",
        "\n",
        "#tính toán confidence của các association rule có 3 phần tử (triple) dựa trên frequent itemsets và frequent pairs đã tính toán trước đó.\n",
        "confidencetri = []\n",
        "for key, val in Frequenttriple.items():\n",
        "    pairA = (key[0], key[1])\n",
        "    prob = val / (1.0 * Frequentpair[pairA])\n",
        "    confidencetri.append((pairA, prob, key[2]))\n",
        "    pairB = (key[0], key[2])\n",
        "    prob = val / (1.0 * Frequentpair[pairB])\n",
        "    confidencetri.append((pairB, prob, key[1]))\n",
        "    pairC = (key[1], key[2])\n",
        "    prob = val / (1.0 * Frequentpair[pairC])\n",
        "    confidencetri.append((pairC, prob, key[0]))\n",
        "\n",
        "confidencetri=list(set(confidencetri))\n",
        "\n",
        "print(\"The top 5 rules are as follows\")\n",
        "sortconfidencetri = sorted(confidencetri, key=lambda x:x[1], reverse = True)\n",
        "for i in range(5):\n",
        "    print(str(sortconfidencetri[i][0][0]) +\", \"+str(sortconfidencetri[i][0][1])+ \"⇒\" + str(sortconfidencetri[i][2]) + \"  \" + str(sortconfidencetri[i][1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cQU_-cpch2B",
        "outputId": "1af44c05-b489-4b91-db3b-d970cc90437a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top 5 rules are as follows\n",
            "GRO38814, GRO85051⇒FRO40251  1.0\n",
            "GRO85051, DAI75645⇒FRO40251  1.0\n",
            "DAI88079, DAI62779⇒FRO40251  1.0\n",
            "DAI55911, GRO85051⇒FRO40251  1.0\n",
            "GRO85051, ELE17451⇒FRO40251  1.0\n"
          ]
        }
      ]
    }
  ]
}